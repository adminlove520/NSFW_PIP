import requests
import threading
import os
import time
import hashlib
import json
from urllib.parse import urlparse
from datetime import datetime, timezone

# å®šä¹‰UTCå¸¸é‡ä»¥å…¼å®¹Python 3.10
UTC = timezone.utc
import signal
import sys
import argparse
import urllib3
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
import uuid
import re
import random

# ç¦ç”¨SSLè­¦å‘Š
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

class VideoDownloader:
    def __init__(self, output_dir="downloads", max_workers=3, max_downloads=None):
        self.output_dir = self.sanitize_path(output_dir)
        self.max_workers = max_workers
        self.max_downloads = max_downloads  # æ·»åŠ æœ€å¤§ä¸‹è½½æ•°é‡é™åˆ¶
        self.downloaded_count = 0
        self.duplicate_count = 0
        self.error_count = 0
        self.total_size = 0
        self.downloaded_hashes = set()
        self.downloaded_urls = set()
        self.running = True
        self.lock = threading.Lock()
        self.api_failures = {}
        self.filename_counter = 0
        
        # æ¯ä¸ªçº¿ç¨‹ç‹¬ç«‹çš„ä¼šè¯
        self.thread_local = threading.local()
        
        # åªä½¿ç”¨ç¨³å®šçš„API
        self.api_urls = [
            # HTTPæ¥å£ï¼ˆæ›´ç¨³å®šï¼‰
            'http://api.xingchenfu.xyz/API/hssp.php',
            'http://api.xingchenfu.xyz/API/wmsc.php',
            'http://api.xingchenfu.xyz/API/tianmei.php',
            'http://api.xingchenfu.xyz/API/cdxl.php',
            'http://api.xingchenfu.xyz/API/yzxl.php',
            'http://api.xingchenfu.xyz/API/rwsp.php',
            'http://api.xingchenfu.xyz/API/nvda.php',
            'http://api.xingchenfu.xyz/API/bsxl.php',
            'http://api.xingchenfu.xyz/API/zzxjj.php',
            'http://api.xingchenfu.xyz/API/qttj.php',
            'http://api.xingchenfu.xyz/API/xqtj.php',
            'http://api.xingchenfu.xyz/API/sktj.php',
            'http://api.xingchenfu.xyz/API/cossp.php',
            'http://api.xingchenfu.xyz/API/xiaohulu.php',
            'http://api.xingchenfu.xyz/API/manhuay.php',
            'http://api.xingchenfu.xyz/API/bianzhuang.php',
            'http://api.xingchenfu.xyz/API/jk.php',
            # ç›¸å¯¹ç¨³å®šçš„HTTPSæ¥å£
            'https://www.hhlqilongzhu.cn/api/MP4_xiaojiejie.php',
            'https://v.api.aa1.cn/api/api-video-qing-chun/index.php',
            'https://api.yujn.cn/api/zzxjj.php?type=video',
            'https://api.jkyai.top/API/jxhssp.php',
            'https://api.jkyai.top/API/jxbssp.php',
            'https://api.jkyai.top/API/rmtmsp/api.php',
            'https://api.jkyai.top/API/qcndxl.php',
        ]
        
        # åˆ›å»ºä¸‹è½½ç›®å½•
        self.ensure_directory(self.output_dir)
        
        # åŠ è½½å·²ä¸‹è½½è®°å½•
        self.load_download_history()
        
        # è®¾ç½®ä¿¡å·å¤„ç†
        signal.signal(signal.SIGINT, self.signal_handler)
        signal.signal(signal.SIGTERM, self.signal_handler)

    def sanitize_path(self, path):
        """æ¸…ç†è·¯å¾„ä¸­çš„ç‰¹æ®Šå­—ç¬¦"""
        path = re.sub(r'[<>:"|?*]', '_', path)
        path = path.replace(' ', '_')
        return path

    def ensure_directory(self, directory):
        """ç¡®ä¿ç›®å½•å­˜åœ¨ä¸”å¯å†™"""
        try:
            os.makedirs(directory, exist_ok=True)
            test_file = os.path.join(directory, 'test_write.tmp')
            with open(test_file, 'w') as f:
                f.write('test')
            os.remove(test_file)
            print(f"âœ“ è¾“å‡ºç›®å½•: {os.path.abspath(directory)}")
        except Exception as e:
            print(f"âŒ ç›®å½•åˆ›å»ºå¤±è´¥: {e}")
            fallback_dir = os.path.join(os.getcwd(), 'video_downloads')
            print(f"ä½¿ç”¨å¤‡ç”¨ç›®å½•: {fallback_dir}")
            os.makedirs(fallback_dir, exist_ok=True)
            self.output_dir = fallback_dir

    def get_session(self):
        """è·å–çº¿ç¨‹æœ¬åœ°çš„session"""
        if not hasattr(self.thread_local, 'session'):
            session = requests.Session()
            
            retry_strategy = Retry(
                total=1,
                backoff_factor=0.3,
                status_forcelist=[429, 500, 502, 503, 504],
                allowed_methods=["HEAD", "GET", "OPTIONS"]
            )
            
            adapter = HTTPAdapter(
                max_retries=retry_strategy,
                pool_maxsize=10,
                pool_block=False
            )
            session.mount("http://", adapter)
            session.mount("https://", adapter)
            
            session.headers.update({
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
                'Accept': '*/*',
                'Connection': 'keep-alive',
            })
            
            self.thread_local.session = session
            
        return self.thread_local.session

    def get_unique_filename(self, extension='.mp4'):
        """ç”Ÿæˆå”¯ä¸€çš„æ–‡ä»¶å"""
        with self.lock:
            self.filename_counter += 1
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            thread_id = threading.current_thread().ident % 1000
            unique_id = f"{timestamp}_{thread_id}_{self.filename_counter:06d}"
            
        filename = f"video_{unique_id}{extension}"
        return filename

    def is_api_available(self, api_url):
        """æ£€æŸ¥APIæ˜¯å¦å¯ç”¨"""
        failure_count = self.api_failures.get(api_url, 0)
        return failure_count < 5

    def mark_api_failure(self, api_url):
        """æ ‡è®°APIå¤±è´¥"""
        with self.lock:
            self.api_failures[api_url] = self.api_failures.get(api_url, 0) + 1

    def mark_api_success(self, api_url):
        """æ ‡è®°APIæˆåŠŸ"""
        with self.lock:
            if api_url in self.api_failures and self.api_failures[api_url] > 0:
                self.api_failures[api_url] -= 1

    def load_download_history(self):
        """åŠ è½½ä¸‹è½½å†å²è®°å½•"""
        history_file = os.path.join(self.output_dir, 'download_history.json')
        if os.path.exists(history_file):
            try:
                with open(history_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    self.downloaded_hashes = set(data.get('hashes', []))
                    self.downloaded_urls = set(data.get('urls', []))
                print(f"âœ“ å·²åŠ è½½ {len(self.downloaded_hashes)} ä¸ªå†å²è®°å½•")
            except Exception as e:
                print(f"âš  åŠ è½½å†å²å¤±è´¥: {e}")

    def save_download_history(self):
        """ä¿å­˜ä¸‹è½½å†å²è®°å½•"""
        history_file = os.path.join(self.output_dir, 'download_history.json')
        try:
            with open(history_file, 'w', encoding='utf-8') as f:
                json.dump({
                    'hashes': list(self.downloaded_hashes),
                    'urls': list(self.downloaded_urls)
                }, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"âš  ä¿å­˜å†å²å¤±è´¥: {e}")

    def signal_handler(self, signum, frame):
        """ä¿¡å·å¤„ç†å‡½æ•°"""
        print("\n\nğŸ“ æ­£åœ¨åœæ­¢...")
        self.running = False
        self.save_download_history()
        print(f"ğŸ“Š æœ€ç»ˆç»Ÿè®¡ - æˆåŠŸ: {self.downloaded_count} | é‡å¤: {self.duplicate_count} | é”™è¯¯: {self.error_count}")
        sys.exit(0)

    def get_video_url(self, api_url):
        """ä»APIè·å–è§†é¢‘URL"""
        if not self.is_api_available(api_url):
            return None
            
        try:
            session = self.get_session()
            
            # æ ¹æ®URLå†³å®šæ˜¯å¦éªŒè¯SSL
            verify_ssl = not any(domain in api_url for domain in [
                'api.jrsg.top', 'api.emoao.com', 'api.caonm.net', 
                'api.linhun.pro', 'api.lolimi.cn'
            ])
            
            response = session.get(
                api_url, 
                timeout=(2, 5),
                allow_redirects=True,
                verify=verify_ssl
            )
            
            if response.status_code == 200:
                self.mark_api_success(api_url)
                
                # è§£æJSONå“åº”
                try:
                    data = response.json()
                    if isinstance(data, dict):
                        for key in ['url', 'video_url', 'data', 'video', 'mp4']:
                            if key in data and isinstance(data[key], str):
                                video_url = data[key].strip()
                                if video_url.startswith('http'):
                                    return video_url
                except:
                    pass
                
                # æ£€æŸ¥ç›´æ¥æ–‡æœ¬å“åº”
                content = response.text.strip()
                if content.startswith('http') and len(content) < 500:
                    return content
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯è§†é¢‘æ–‡ä»¶é‡å®šå‘
                content_type = response.headers.get('content-type', '').lower()
                if 'video' in content_type:
                    return response.url
                    
            else:
                self.mark_api_failure(api_url)
                
            return None
            
        except Exception:
            self.mark_api_failure(api_url)
            return None

    def download_video(self, video_url):
        """ä¸‹è½½è§†é¢‘"""
        if not self.running or video_url in self.downloaded_urls:
            if video_url in self.downloaded_urls:
                with self.lock:
                    self.duplicate_count += 1
            return False

        try:
            session = self.get_session()
            
            # HEADè¯·æ±‚è·å–æ–‡ä»¶ä¿¡æ¯
            head_response = session.head(
                video_url, 
                timeout=(3, 8), 
                allow_redirects=True
            )
            
            if head_response.status_code not in [200, 206]:
                return False
                
            content_length = int(head_response.headers.get('content-length', 0))
            content_type = head_response.headers.get('content-type', '')
            
            # ç¡®å®šæ–‡ä»¶æ‰©å±•å
            extension = '.mp4'
            if 'avi' in content_type.lower():
                extension = '.avi'
            elif 'mov' in content_type.lower():
                extension = '.mov'
            elif 'webm' in content_type.lower():
                extension = '.webm'
                
            filename = self.get_unique_filename(extension)
            file_path = os.path.join(self.output_dir, filename)
            temp_path = file_path + '.tmp'
            
            # æ£€æŸ¥æ–­ç‚¹ç»­ä¼ 
            resume_pos = 0
            if os.path.exists(temp_path):
                resume_pos = os.path.getsize(temp_path)
                if content_length > 0 and resume_pos >= content_length:
                    os.remove(temp_path)
                    resume_pos = 0
            
            # ä¸‹è½½è¯·æ±‚
            headers = {}
            if resume_pos > 0:
                headers['Range'] = f'bytes={resume_pos}-'
            
            response = session.get(
                video_url, 
                headers=headers, 
                stream=True, 
                timeout=(5, 30)
            )
            
            if response.status_code not in [200, 206]:
                return False
            
            # å†™å…¥æ–‡ä»¶
            downloaded_size = resume_pos
            with open(temp_path, 'ab' if resume_pos > 0 else 'wb') as f:
                for chunk in response.iter_content(chunk_size=8192):
                    if not self.running:
                        return False
                    if chunk:
                        f.write(chunk)
                        downloaded_size += len(chunk)
            
            # æ£€æŸ¥æ–‡ä»¶å®Œæ•´æ€§
            if content_length > 0 and downloaded_size < content_length * 0.8:
                if os.path.exists(temp_path):
                    os.remove(temp_path)
                return False
            
            # ç§»åŠ¨åˆ°æœ€ç»ˆä½ç½®
            try:
                os.rename(temp_path, file_path)
            except OSError:
                if os.path.exists(temp_path):
                    os.remove(temp_path)
                return False
            
            # æ£€æŸ¥é‡å¤
            file_hash = self.get_file_hash(file_path)
            if file_hash and file_hash in self.downloaded_hashes:
                os.remove(file_path)
                with self.lock:
                    self.duplicate_count += 1
                return False
            
            # è®°å½•æˆåŠŸ
            with self.lock:
                self.downloaded_count += 1
                self.total_size += downloaded_size
                if file_hash:
                    self.downloaded_hashes.add(file_hash)
                self.downloaded_urls.add(video_url)
            
            print(f"âœ“ {filename} ({self.format_size(downloaded_size)})")
            return True
            
        except Exception as e:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if 'temp_path' in locals() and os.path.exists(temp_path):
                try:
                    os.remove(temp_path)
                except:
                    pass
            
            with self.lock:
                self.error_count += 1
            return False

    def get_file_hash(self, file_path):
        """è®¡ç®—æ–‡ä»¶MD5å“ˆå¸Œ"""
        try:
            hasher = hashlib.md5()
            with open(file_path, 'rb') as f:
                for chunk in iter(lambda: f.read(8192), b""):
                    hasher.update(chunk)
            return hasher.hexdigest()
        except:
            return None

    def format_size(self, size_bytes):
        """æ ¼å¼åŒ–æ–‡ä»¶å¤§å°"""
        if size_bytes == 0:
            return "0 B"
        size_names = ["B", "KB", "MB", "GB"]
        i = 0
        while size_bytes >= 1024 and i < len(size_names) - 1:
            size_bytes /= 1024.0
            i += 1
        return f"{size_bytes:.1f} {size_names[i]}"

    def get_available_apis(self):
        """è·å–å¯ç”¨APIåˆ—è¡¨"""
        return [api for api in self.api_urls if self.is_api_available(api)]

    def worker_thread(self, thread_id):
        """å·¥ä½œçº¿ç¨‹ - æ¯ä¸ªçº¿ç¨‹ç‹¬ç«‹å·¥ä½œï¼Œä¸ç­‰å¾…å…¶ä»–çº¿ç¨‹"""
        print(f"ğŸ¯ çº¿ç¨‹ {thread_id} å¯åŠ¨")
        
        while self.running:
            # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°æœ€å¤§ä¸‹è½½æ•°é‡
            with self.lock:
                if self.max_downloads is not None and self.downloaded_count >= self.max_downloads:
                    self.running = False
                    break
            
            try:
                # è·å–å¯ç”¨API
                available_apis = self.get_available_apis()
                if not available_apis:
                    # å¦‚æœæ²¡æœ‰å¯ç”¨APIï¼Œé‡ç½®å¤±è´¥è®¡æ•°å™¨å¹¶çŸ­æš‚ç­‰å¾…
                    time.sleep(2)
                    with self.lock:
                        self.api_failures = {k: max(0, v-1) for k, v in self.api_failures.items()}
                    continue
                
                # éšæœºé€‰æ‹©APIå¹¶è·å–è§†é¢‘URL
                api_url = random.choice(available_apis)
                video_url = self.get_video_url(api_url)
                
                if video_url and self.running:
                    # ç«‹å³ä¸‹è½½ï¼Œä¸ç­‰å¾…å…¶ä»–çº¿ç¨‹
                    self.download_video(video_url)
                    # ä¸‹è½½å®Œæˆåç«‹å³ç»§ç»­ä¸‹ä¸€ä¸ªï¼Œåªæœ‰å¾ˆçŸ­çš„é—´éš”é¿å…è¿‡äºé¢‘ç¹
                    time.sleep(0.1)
                else:
                    # å¦‚æœè·å–URLå¤±è´¥ï¼Œç¨å¾®ç­‰å¾…ä¸€ä¸‹å†è¯•ä¸‹ä¸€ä¸ªAPI
                    time.sleep(0.5)
                
            except Exception:
                # å‡ºç°å¼‚å¸¸æ—¶çŸ­æš‚ç­‰å¾…
                time.sleep(1)

    def print_status(self):
        """çŠ¶æ€æ˜¾ç¤º"""
        while self.running:
            available_count = len(self.get_available_apis())
            with self.lock:
                print(f"\rğŸ“Š æˆåŠŸ:{self.downloaded_count} é‡å¤:{self.duplicate_count} "
                      f"é”™è¯¯:{self.error_count} å¤§å°:{self.format_size(self.total_size)} "
                      f"API:{available_count}/{len(self.api_urls)}", end='', flush=True)
            time.sleep(1)

    def start_download(self):
        """å¼€å§‹ä¸‹è½½"""
        print(f"ğŸš€ å¯åŠ¨ä¸‹è½½å™¨ (çº¿ç¨‹æ•°: {self.max_workers})")
        print("â¹ Ctrl+C åœæ­¢")
        print("ğŸ”„ æ¯ä¸ªçº¿ç¨‹ç‹¬ç«‹å·¥ä½œï¼Œä¸‹å®Œç«‹å³ç»§ç»­\n")
        
        # å¯åŠ¨çŠ¶æ€æ˜¾ç¤ºçº¿ç¨‹
        status_thread = threading.Thread(target=self.print_status, daemon=True)
        status_thread.start()
        
        # å¯åŠ¨å·¥ä½œçº¿ç¨‹ï¼Œæ¯ä¸ªçº¿ç¨‹ç‹¬ç«‹å·¥ä½œ
        threads = []
        for i in range(self.max_workers):
            thread = threading.Thread(target=self.worker_thread, args=(i+1,), daemon=True)
            thread.start()
            threads.append(thread)
        
        try:
            # ä¸»çº¿ç¨‹ç­‰å¾…ï¼Œä½†ä¸å¹²é¢„å·¥ä½œçº¿ç¨‹
            while self.running:
                time.sleep(1)
                # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰çº¿ç¨‹éƒ½è¿˜æ´»ç€
                if not any(t.is_alive() for t in threads):
                    print("\næ‰€æœ‰çº¿ç¨‹å·²ç»“æŸ")
                    break
        except KeyboardInterrupt:
            self.signal_handler(signal.SIGINT, None)
        finally:
            # ç¡®ä¿åœ¨ä»»ä½•æƒ…å†µä¸‹éƒ½ä¿å­˜å†å²è®°å½•
            if not self.running:  # å¦‚æœæ˜¯æ­£å¸¸ç»“æŸæˆ–è¾¾åˆ°ä¸‹è½½é™åˆ¶
                self.save_download_history()
                print(f"\nğŸ“ ä¸‹è½½å®Œæˆï¼Œå·²ä¿å­˜å†å²è®°å½•")
                print(f"ğŸ“Š æœ€ç»ˆç»Ÿè®¡ - æˆåŠŸ: {self.downloaded_count} | é‡å¤: {self.duplicate_count} | é”™è¯¯: {self.error_count}")

def main():
    parser = argparse.ArgumentParser(description='ğŸ¬ å¤šçº¿ç¨‹è§†é¢‘ä¸‹è½½å™¨')
    parser.add_argument('-o', '--output', default='downloads', help='è¾“å‡ºç›®å½•')
    parser.add_argument('-t', '--threads', type=int, default=3, help='çº¿ç¨‹æ•° (é»˜è®¤: 3)')
    parser.add_argument('-n', '--max-downloads', type=int, default=None, help='æœ€å¤§ä¸‹è½½æ•°é‡')
    parser.add_argument('--date-subdir', action='store_true', help='æ˜¯å¦åœ¨è¾“å‡ºç›®å½•ä¸‹åˆ›å»ºæ—¥æœŸå­ç›®å½•')
    
    args = parser.parse_args()
    
    if args.threads < 1 or args.threads > 16:
        print("âŒ çº¿ç¨‹æ•°åº”åœ¨1-16ä¹‹é—´")
        return
    
    # å¤„ç†æ—¥æœŸå­ç›®å½•
    output_dir = args.output
    if args.date_subdir:
        date_str = datetime.now(UTC).strftime("%Y%m%d")
        output_dir = os.path.join(output_dir, f"é›…ä¿—å…±èµ_{date_str}")
    
    try:
        downloader = VideoDownloader(
            output_dir=output_dir, 
            max_workers=args.threads,
            max_downloads=args.max_downloads
        )
        downloader.start_download()
    except Exception as e:
        print(f"âŒ ç¨‹åºé”™è¯¯: {e}")

if __name__ == "__main__":
    main()